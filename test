import sys
import subprocess
import time
import statistics
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import parse_qsl
import json
import requests
requests.packages.urllib3.disable_warnings()

# Configuration
URL_AUTH = "https:///token"
URL_PROCESSING = "https:///triggerMailBox"
URL_API = "https:///profiles/{processUid}"
USERNAME = ""
PASSWORD = ""
BODY = "t"
PFX_PATH = ""
PFX_PASSPHRASE = ""
VERIFY_SSL = True

# Performance Test Configuration
TEST_DURATION = 30  # seconds
MAX_THREADS = 50    # Can be set to 50, 100, or 200
WARMUP_REQUESTS = 5
TOKEN_REFRESH_TIME = 20  # seconds

def ensure_requests_pkcs12():
    try:
        import requests_pkcs12
        return requests_pkcs12
    except ImportError:
        subprocess.check_call([sys.executable, "-m", "pip", "install", "requests_pkcs12"])
        import requests_pkcs12
        return requests_pkcs12

def load_body(body_arg):
    try:
        with open(body_arg, "r", encoding="utf-8") as f:
            raw = f.read().strip()
    except (OSError, IOError):
        raw = body_arg.strip()
    pairs = parse_qsl(raw, keep_blank_values=True)
    return dict(pairs)

class TokenManager:
    def __init__(self, requests_pkcs12):
        self.requests_pkcs12 = requests_pkcs12
        self.token = None
        self.token_timestamp = 0
        self.lock = threading.Lock()
    
    def get_token(self):
        with self.lock:
            current_time = time.time()
            if self.token is None or (current_time - self.token_timestamp) > TOKEN_REFRESH_TIME:
                print("Refreshing token...")
                self.token = self._fetch_new_token()
                self.token_timestamp = current_time
            return self.token
    
    def _fetch_new_token(self):
        data = load_body(BODY)
        try:
            response = self.requests_pkcs12.post(
                URL_AUTH,
                auth=(USERNAME, PASSWORD),
                data=data,
                headers={"Content-Type": "application/x-www-form-urlencoded"},
                pkcs12_filename=PFX_PATH,
                pkcs12_password=PFX_PASSPHRASE,
                verify=VERIFY_SSL,
                timeout=30
            )
            response.raise_for_status()
            return response.json().get("access_token")
        except Exception as e:
            print(f"Token fetch failed: {str(e)}", file=sys.stderr)
            return None

def get_processUid(requests_pkcs12, token):
    headers = {
        "Authorization": f"Bearer {token}",
        "Accept": "application/json"
    }
    try:
        response = requests_pkcs12.get(
            URL_PROCESSING,
            headers=headers,
            pkcs12_filename=PFX_PATH,
            pkcs12_password=PFX_PASSPHRASE,
            verify=VERIFY_SSL,
            timeout=30
        )
        response.raise_for_status()
        processUid = response.json().get("processUid")
        print(f"Generated processUid: {processUid}")  # Print when generated
        return processUid
    except Exception as e:
        print(f"Failed to get processUid: {str(e)}", file=sys.stderr)
        return None

def check_status(requests_pkcs12, token, processUid):
    headers = {
        "Authorization": f"Bearer {token}",
        "Accept": "application/json"
    }
    try:
        response = requests_pkcs12.get(
            URL_API.format(processUid=processUid),
            headers=headers,
            pkcs12_filename=PFX_PATH,
            pkcs12_password=PFX_PASSPHRASE,
            verify=VERIFY_SSL,
            timeout=30
        )
        # Print status code directly
        print(f"processUid: {processUid} = {response.status_code} {response.reason}")
        return response.status_code == 200
    except Exception as e:
        print(f"processUid: {processUid} = Error: {str(e)}")
        return False

def worker(requests_pkcs12, token_manager, process_uids, results, stop_event):
    while not stop_event.is_set():
        token = token_manager.get_token()
        if not token:
            time.sleep(1)
            continue
        
        processUid = get_processUid(requests_pkcs12, token)
        if not processUid:
            continue
        
        with process_uids["lock"]:
            process_uids["ids"].append(processUid)
        
        start_time = time.time()
        try:
            headers = {
                "Authorization": f"Bearer {token}",
                "Accept": "application/json"
            }
            response = requests_pkcs12.get(
                URL_API.format(processUid=processUid),
                headers=headers,
                pkcs12_filename=PFX_PATH,
                pkcs12_password=PFX_PASSPHRASE,
                verify=VERIFY_SSL,
                timeout=30
            )
            elapsed = time.time() - start_time
            
            # Print immediate response status
            print(f"processUid: {processUid} = {response.status_code} {response.reason}")
            
            with results["lock"]:
                results["total_requests"] += 1
                if response.status_code == 200:
                    results["successful_requests"] += 1
                else:
                    results["failed_requests"] += 1
                results["response_times"].append(elapsed)
        except Exception as e:
            elapsed = time.time() - start_time
            print(f"processUid: {processUid} = Error: {str(e)}")
            with results["lock"]:
                results["total_requests"] += 1
                results["failed_requests"] += 1
                results["response_times"].append(elapsed)

def monitor_statuses(requests_pkcs12, token_manager, process_uids, stop_event):
    while not stop_event.is_set() or process_uids["ids"]:
        time.sleep(1)  # Check every second
        
        token = token_manager.get_token()
        if not token:
            continue
            
        with process_uids["lock"]:
            current_uids = process_uids["ids"].copy()
        
        for uid in current_uids:
            if check_status(requests_pkcs12, token, uid):
                with process_uids["lock"]:
                    if uid in process_uids["ids"]:
                        process_uids["ids"].remove(uid)

def run_performance_test(requests_pkcs12):
    test_start_time = time.time()
    token_manager = TokenManager(requests_pkcs12)
    
    results = {
        "total_requests": 0,
        "successful_requests": 0,
        "failed_requests": 0,
        "response_times": [],
        "test_start_time": test_start_time,
        "test_end_time": 0,
        "lock": threading.Lock()
    }
    
    process_uids = {
        "ids": [],
        "lock": threading.Lock()
    }
    
    stop_event = threading.Event()
    monitor_thread = threading.Thread(
        target=monitor_statuses,
        args=(requests_pkcs12, token_manager, process_uids, stop_event)
    )
    monitor_thread.daemon = True
    monitor_thread.start()
    
    # Warmup phase
    print(f"Running {WARMUP_REQUESTS} warmup requests...")
    warmup_threads = min(WARMUP_REQUESTS, MAX_THREADS)
    with ThreadPoolExecutor(max_workers=warmup_threads) as executor:
        futures = [executor.submit(
            worker, requests_pkcs12, token_manager, process_uids, results, threading.Event()
        ) for _ in range(WARMUP_REQUESTS)]
        for future in as_completed(futures):
            future.result()
    
    print(f"Starting main test with {MAX_THREADS} threads for {TEST_DURATION} seconds...")
    with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:
        futures = [executor.submit(
            worker, requests_pkcs12, token_manager, process_uids, results, stop_event
        ) for _ in range(MAX_THREADS)]
        
        # Let the test run for the specified duration
        time.sleep(TEST_DURATION)
        stop_event.set()
        
        for future in as_completed(futures):
            future.result()
    
    results["test_end_time"] = time.time()
    
    # Final wait for completion
    print("Waiting for remaining processes to complete...")
    wait_start = time.time()
    while time.time() - wait_start < 30 and process_uids["ids"]:
        time.sleep(1)
    
    with process_uids["lock"]:
        if process_uids["ids"]:
            print(f"Warning: {len(process_uids['ids'])} processes did not complete")
    
    monitor_thread.join(timeout=5)
    return results

def analyze_results(results):
    if not results or results["total_requests"] == 0:
        return None

    actual_duration = results["test_end_time"] - results["test_start_time"]
    requests_per_second = results["total_requests"] / actual_duration
    error_rate = (results["failed_requests"] / results["total_requests"]) * 100 if results["total_requests"] > 0 else 0

    if results["response_times"]:
        avg_response_time = statistics.mean(results["response_times"])
        min_response_time = min(results["response_times"])
        max_response_time = max(results["response_times"])
        percentile_95 = statistics.quantiles(results["response_times"], n=100)[-1] if len(results["response_times"]) > 1 else results["response_times"][0]
    else:
        avg_response_time = min_response_time = max_response_time = percentile_95 = 0

    return {
        "total_test_duration_seconds": actual_duration,
        "total_requests": results["total_requests"],
        "successful_requests": results["successful_requests"],
        "failed_requests": results["failed_requests"],
        "error_rate_percent": error_rate,
        "requests_per_second": requests_per_second,
        "avg_response_time_seconds": avg_response_time,
        "min_response_time_seconds": min_response_time,
        "max_response_time_seconds": max_response_time,
        "95th_percentile_seconds": percentile_95
    }

def main():
    requests_pkcs12 = ensure_requests_pkcs12()
    test_results = run_performance_test(requests_pkcs12)
    if not test_results:
        print("Performance test failed to produce results", file=sys.stderr)
        return None
    analysis = analyze_results(test_results)
    print("\nPerformance Test Results:")
    print(json.dumps(analysis, indent=2))
    return analysis

if __name__ == "__main__":
    main()
