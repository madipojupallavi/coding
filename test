
    def calculate_metrics(self, data, time_field, size_field=None):
        success_data = [d for d in data if d.get("success", False)]
        success_times = [d[time_field] for d in success_data if time_field in d]
        
        metrics = {
            "count": len(data),
            "success_count": len(success_data),
            "error_count": len(data) - len(success_data),
            "error_rate": (len(data) - len(success_data)) / len(data) * 100 if len(data) > 0 else 0,
            "avg": statistics.mean(success_times) if success_times else 0,
            "min": min(success_times) if success_times else 0,
            "max": max(success_times) if success_times else 0,
            "median": statistics.median(success_times) if success_times else 0,
            "p90": statistics.quantiles(success_times, n=10)[8] if len(success_times) >= 10 else 0,
            "p95": statistics.quantiles(success_times, n=20)[18] if len(success_times) >= 20 else 0,
            "p99": statistics.quantiles(success_times, n=100)[98] if len(success_times) >= 100 else 0,
        }
        
        if size_field:
            total_request_size = sum(d.get("request_size_bytes", 0) for d in data)
            total_response_size = sum(d.get("response_size_bytes", 0) for d in data)
            metrics.update({
                "total_request_kb": total_request_size / 1024,
                "total_response_kb": total_response_size / 1024,
                "avg_request_kb": (total_request_size / len(data)) / 1024 if len(data) > 0 else 0,
                "avg_response_kb": (total_response_size / len(data)) / 1024 if len(data) > 0 else 0,
            })
        
        return metrics

    def generate_report(self, test_duration):
        try:
            print(f"\nüìä Generating comprehensive report at: {OUTPUT_EXCEL}")
            
            # Calculate metrics for each endpoint
            token_metrics = self.calculate_metrics(self.token_manager.token_stats, "response_time", "request_size_bytes")
            processing_metrics = self.calculate_metrics(self.processing_stats, "response_time", "request_size_bytes")
            api_metrics = self.calculate_metrics(self.api_stats, "response_time", "request_size_bytes")
            
            # Calculate throughput and KB/sec for each endpoint
            for metrics in [token_metrics, processing_metrics, api_metrics]:
                metrics["throughput"] = metrics["count"] / test_duration
                metrics["received_kb_sec"] = metrics["total_response_kb"] / test_duration
                metrics["sent_kb_sec"] = metrics["total_request_kb"] / test_duration

            # Create a new Excel workbook with single sheet for all metrics
            wb = Workbook()
            ws = wb.active
            ws.title = "Performance Metrics"
            
            # Header style
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(start_color="4F81BD", end_color="4F81BD", fill_type="solid")
            
            # Endpoint headers
            endpoints = ["Token Endpoint", "ProcessID Endpoint", "API Endpoint"]
            ws.append([""] + endpoints)
            
            # Apply header style
            for cell in ws[1]:
                cell.font = header_font
                cell.fill = header_fill
            
            # Metrics to display (in order)
            metric_rows = [
                ("Total Requests", "count"),
                ("Successful Requests", "success_count"),
                ("Failed Requests", "error_count"),
                ("Error Rate (%)", "error_rate", lambda x: f"{x:.2f}%"),
                ("Average Latency (s)", "avg", lambda x: f"{x:.4f}"),
                ("Minimum Latency (s)", "min", lambda x: f"{x:.4f}"),
                ("Maximum Latency (s)", "max", lambda x: f"{x:.4f}"),
                ("Median Latency (s)", "median", lambda x: f"{x:.4f}"),
                ("90th Percentile (s)", "p90", lambda x: f"{x:.4f}"),
                ("95th Percentile (s)", "p95", lambda x: f"{x:.4f}"),
                ("99th Percentile (s)", "p99", lambda x: f"{x:.4f}"),
                ("Throughput (requests/sec)", "throughput", lambda x: f"{x:.2f}"),
                ("Total Sent (KB)", "total_request_kb", lambda x: f"{x:.2f}"),
                ("Total Received (KB)", "total_response_kb", lambda x: f"{x:.2f}"),
                ("Send Rate (KB/sec)", "sent_kb_sec", lambda x: f"{x:.2f}"),
                ("Receive Rate (KB/sec)", "received_kb_sec", lambda x: f"{x:.2f}")
            ]
            
            # Add all metrics
            for label, metric_key, *formatter in metric_rows:
                formatter = formatter[0] if formatter else lambda x: x
                row = [label]
                for metrics in [token_metrics, processing_metrics, api_metrics]:
                    value = metrics.get(metric_key, 0)
                    row.append(formatter(value))
                ws.append(row)
            
            # Add summary section
            ws.append([])  # Empty row
            ws.append(["Test Summary"])
            ws.append(["Test Duration (seconds)", test_duration])
            ws.append(["Total Threads", MAX_THREADS])
            ws.append(["Total Tokens Generated", self.token_manager.total_tokens_generated])
            ws.append(["Total Process IDs Generated", len(self.processing_stats)])
            ws.append(["Total API Calls", len(self.api_stats)])
            ws.append(["Total Successful Transactions", len([r for r in self.results if r["success"]])])
            ws.append(["Total Failed Transactions", len([r for r in self.results if not r["success"]])])
            ws.append(["Overall Error Rate", f"{((len(self.results) - len([r for r in self.results if r['success']])) / len(self.results) * 100 if len(self.results) > 0 else 0):.2f}%"])
            ws.append(["Overall Throughput (requests/sec)", f"{len(self.results) / test_duration:.2f}"])
            
            # Formatting
            for col in ws.columns:
                max_length = 0
                column = col[0].column_letter
                for cell in col:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = (max_length + 2)
                ws.column_dimensions[column].width = adjusted_width
            
            # Add borders to metrics table
            from openpyxl.styles import Border, Side
            thin_border = Border(left=Side(style='thin'), 
                                right=Side(style='thin'), 
                                top=Side(style='thin'), 
                                bottom=Side(style='thin'))
            
            for row in ws.iter_rows(min_row=1, max_row=len(metric_rows)+1, max_col=4):
                for cell in row:
                    cell.border = thin_border
            
            # Save the workbook
            wb.save(OUTPUT_EXCEL)
            print("‚úÖ Comprehensive report generated successfully")
            
        except PermissionError:
            print(f"‚ùå ERROR: Please close Excel file if open: {OUTPUT_EXCEL}")
            raise
        except Exception as e:
            print(f"‚ùå Failed to generate report: {str(e)}")
            raise

   
import sys
import subprocess
import time
import json
import requests
import threading
import queue
import statistics
from datetime import datetime, timedelta
from openpyxl import Workbook
from openpyxl.styles import Font, PatternFill, Border, Side
from concurrent.futures import ThreadPoolExecutor, as_completed

# Configuration
URL_AUTH = "https:///token"
URL_PROCESSING = "https:///triggerMailBox"
URL_API = "https:///profiles/{processUid}"
USERNAME = ""
PASSWORD = ""
BODY = "t"
PFX_PATH = ""
PFX_PASSPHRASE = ""
VERIFY_SSL = True
OUTPUT_EXCEL = f"performance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"

# Test Configuration
TOKEN_EXPIRY_SECONDS = 20  # Token expires after 20 seconds
POLLING_TIMEOUT = 300  # seconds (5 minutes)
POLLING_INTERVAL = 5  # seconds
MAX_THREADS = 50  # Number of concurrent threads

class TokenManager:
    def __init__(self):
        self.requests_pkcs12 = self._ensure_requests_pkcs12()
        self.token = None
        self.token_expiry = None
        self.token_lock = threading.Lock()
        self.token_stats = []
        self.total_tokens_generated = 0

    def _ensure_requests_pkcs12(self):
        try:
            import requests_pkcs12
            return requests_pkcs12
        except ImportError:
            subprocess.check_call([sys.executable, "-m", "pip", "install", "requests_pkcs12"])
            import requests_pkcs12
            return requests_pkcs12

    def _fetch_new_token(self):
        start_time = time.time()
        data = {"grant_type": "client_credentials"}
        try:
            response = self.requests_pkcs12.post(
                URL_AUTH,
                auth=(USERNAME, PASSWORD),
                data=data,
                headers={"Content-Type": "application/x-www-form-urlencoded"},
                pkcs12_filename=PFX_PATH,
                pkcs12_password=PFX_PASSPHRASE,
                verify=VERIFY_SSL,
                timeout=30
            )
            response.raise_for_status()
            token = response.json().get("access_token")
            elapsed = time.time() - start_time
            
            with self.token_lock:
                self.token_stats.append({
                    "timestamp": datetime.now().isoformat(),
                    "response_time": elapsed,
                    "http_status": f"{response.status_code} {response.reason}",
                    "success": True,
                    "request_size_bytes": len(str(data)),
                    "response_size_bytes": len(response.text)
                })
                self.total_tokens_generated += 1
                self.token = token
                self.token_expiry = datetime.now() + timedelta(seconds=TOKEN_EXPIRY_SECONDS)
                print(f"New token generated (Expires at: {self.token_expiry})")
            
            return token
        except Exception as e:
            elapsed = time.time() - start_time
            with self.token_lock:
                self.token_stats.append({
                    "timestamp": datetime.now().isoformat(),
                    "response_time": elapsed,
                    "http_status": str(e),
                    "success": False,
                    "request_size_bytes": len(str(data)),
                    "response_size_bytes": 0
                })
            print(f"Token generation failed: {str(e)}")
            return None

    def get_valid_token(self):
        with self.token_lock:
            # If no token or token expired, generate new one
            if self.token is None or datetime.now() >= self.token_expiry:
                return self._fetch_new_token()
            return self.token

class TestRunner:
    def __init__(self):
        self.token_manager = TokenManager()
        self.processing_stats = []
        self.api_stats = []
        self.results = []
        self.stats_lock = threading.Lock()
        self.queue = queue.Queue()

    def generate_process_id(self):
        token = self.token_manager.get_valid_token()
        if not token:
            return None

        start_time = time.time()
        headers = {"Authorization": f"Bearer {token}", "Accept": "application/json"}
        try:
            response = self.token_manager.requests_pkcs12.post(
                URL_PROCESSING,
                headers=headers,
                pkcs12_filename=PFX_PATH,
                pkcs12_password=PFX_PASSPHRASE,
                verify=VERIFY_SSL,
                timeout=30
            )
            response.raise_for_status()
            elapsed = time.time() - start_time
            
            with self.stats_lock:
                self.processing_stats.append({
                    "timestamp": datetime.now().isoformat(),
                    "response_time": elapsed,
                    "http_status": f"{response.status_code} {response.reason}",
                    "success": True,
                    "request_size_bytes": len(BODY),
                    "response_size_bytes": len(response.text),
                    "token_expiry": self.token_manager.token_expiry.isoformat() if self.token_manager.token_expiry else None
                })
            
            return response.json().get("processUid")
        except Exception as e:
            elapsed = time.time() - start_time
            with self.stats_lock:
                self.processing_stats.append({
                    "timestamp": datetime.now().isoformat(),
                    "response_time": elapsed,
                    "http_status": str(e),
                    "success": False,
                    "request_size_bytes": len(BODY),
                    "response_size_bytes": 0,
                    "token_expiry": self.token_manager.token_expiry.isoformat() if self.token_manager.token_expiry else None
                })
            print(f"ProcessID generation failed: {str(e)}")
            return None

    def check_api_status(self, process_id):
        start_time = time.time()
        elapsed = 0
        api_calls = 0
        success = False
        final_status = "Timeout"
        
        while elapsed < POLLING_TIMEOUT:
            # Get valid token for each API call (will reuse if not expired)
            token = self.token_manager.get_valid_token()
            if not token:
                final_status = "Token Generation Failed"
                break
                
            headers = {"Authorization": f"Bearer {token}", "Accept": "application/json"}
            
            try:
                call_start = time.time()
                response = self.token_manager.requests_pkcs12.get(
                    URL_API.format(processUid=process_id),
                    headers=headers,
                    pkcs12_filename=PFX_PATH,
                    pkcs12_password=PFX_PASSPHRASE,
                    verify=VERIFY_SSL,
                    timeout=30
                )
                call_elapsed = time.time() - call_start
                api_calls += 1
                current_time = time.time()
                elapsed = current_time - start_time
                
                with self.stats_lock:
                    self.api_stats.append({
                        "timestamp": datetime.now().isoformat(),
                        "response_time": call_elapsed,
                        "http_status": f"{response.status_code} {response.reason}",
                        "success": response.status_code == 200,
                        "request_size_bytes": 0,
                        "response_size_bytes": len(response.text),
                        "process_id": process_id,
                        "attempt": api_calls,
                        "token_expiry": self.token_manager.token_expiry.isoformat() if self.token_manager.token_expiry else None
                    })
                
                if response.status_code == 200:
                    json_response = response.json()
                    if 'content' in json_response and 'status' in json_response['content']:
                        status = json_response['content']['status']
                        if status == 'Completed':
                            final_status = status
                            success = True
                            break
                        else:
                            print(f"[{process_id}] Current status: {status}, retrying in {POLLING_INTERVAL}s (Elapsed: {elapsed:.2f}s)")
                    else:
                        print(f"[{process_id}] Response missing content or status, retrying...")
                else:
                    print(f"[{process_id}] Non-200 response: {response.status_code} {response.reason}, retrying in {POLLING_INTERVAL}s")
                
                time.sleep(POLLING_INTERVAL)
                
            except Exception as e:
                call_elapsed = time.time() - call_start
                api_calls += 1
                with self.stats_lock:
                    self.api_stats.append({
                        "timestamp": datetime.now().isoformat(),
                        "response_time": call_elapsed,
                        "http_status": str(e),
                        "success": False,
                        "request_size_bytes": 0,
                        "response_size_bytes": 0,
                        "process_id": process_id,
                        "attempt": api_calls,
                        "token_expiry": self.token_manager.token_expiry.isoformat() if self.token_manager.token_expiry else None
                    })
                print(f"[{process_id}] API call failed: {str(e)}, retrying in {POLLING_INTERVAL}s")
                time.sleep(POLLING_INTERVAL)
                elapsed = time.time() - start_time
        
        result = {
            "process_id": process_id,
            "success": success,
            "total_time": elapsed,
            "api_calls": api_calls,
            "final_status": final_status,
            "start_time": datetime.fromtimestamp(start_time).isoformat(),
            "end_time": datetime.now().isoformat()
        }
        
        with self.stats_lock:
            self.results.append(result)
        
        return result

    def worker(self):
        while True:
            try:
                task = self.queue.get_nowait()
            except queue.Empty:
                break
                
            try:
                process_id = self.generate_process_id()
                if process_id:
                    result = self.check_api_status(process_id)
                    print(f"Process {process_id} completed with status {result['final_status']} in {result['total_time']:.2f}s")
                else:
                    with self.stats_lock:
                        self.results.append({
                            "process_id": "N/A",
                            "success": False,
                            "total_time": 0,
                            "api_calls": 0,
                            "final_status": "ProcessID Generation Failed",
                            "start_time": datetime.now().isoformat(),
                            "end_time": datetime.now().isoformat()
                        })
            finally:
                self.queue.task_done()

    # [Previous calculate_metrics and generate_report methods remain the same]
    # ... (include the exact same methods from previous implementation)

    def run_test(self):
        print(f"üöÄ Starting performance test with {MAX_THREADS} threads...")
        start_time = time.time()
        
        # Enqueue tasks
        for _ in range(MAX_THREADS):
            self.queue.put(None)
            
        # Create and start worker threads
        threads = []
        for _ in range(MAX_THREADS):
            t = threading.Thread(target=self.worker)
            t.start()
            threads.append(t)
        
        # Wait for all threads to complete
        for t in threads:
            t.join()
        
        test_duration = time.time() - start_time
        
        # Generate report
        print("\nüìà Test completed. Generating report...")
        self.generate_report(test_duration)
        
        print("\n=== TEST SUMMARY ===")
        print(f"Total test duration: {test_duration:.2f} seconds")
        print(f"Total processes attempted: {len(self.results)}")
        print(f"Successful processes: {len([r for r in self.results if r['success']])}")
        print(f"Failed processes: {len([r for r in self.results if not r['success']])}")
        print(f"Tokens generated: {self.token_manager.total_tokens_generated}")
        print(f"Report saved to: {OUTPUT_EXCEL}")

if __name__ == "__main__":
    test = TestRunner()
    test.run_test()
